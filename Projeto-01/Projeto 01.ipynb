{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b345de8e",
   "metadata": {},
   "source": [
    "Projeto 01 - Análise Quantitativa de Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa562ce",
   "metadata": {},
   "source": [
    "Início do processamento do corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler(nome_arquivo):\n",
    "  arquivo = open(nome_arquivo,'r', encoding='utf-8')\n",
    "  conteudo_arq = arquivo.read()\n",
    "  arquivo.close()\n",
    "  return conteudo_arq\n",
    "\n",
    "texto = ler('/content/Ubirajara.txt')\n",
    "print(len(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44f820",
   "metadata": {},
   "source": [
    "Primeira Etapa - Buscador de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscador(alvo, texto):\n",
    "  texto = texto.replace('\\n', ' ')\n",
    "  texto = texto.replace('\\t', ' ')\n",
    "\n",
    "  ocorrencias = []\n",
    "  encontrado_aqui = texto.find(alvo, 0)\n",
    "\n",
    "  while encontrado_aqui > 0:\n",
    "    pos_inicial = encontrado_aqui - (40 - len(alvo))\n",
    "    trecho = texto[pos_inicial: pos_inicial + 80]\n",
    "\n",
    "    ocorrencias.append(trecho)\n",
    "\n",
    "    encontrado_aqui = texto.find(alvo, encontrado_aqui + 1)\n",
    "\n",
    "  return ocorrencias\n",
    "\n",
    "resultados = buscador('peito', texto)\n",
    "for trecho in resultados:\n",
    "  print(trecho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5e872",
   "metadata": {},
   "source": [
    "Segunda Etapa - Limpeza dos Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed531553",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = texto.split()\n",
    "\n",
    "def limpar(lista):\n",
    "  lixo = '.,:;?!\"`()[]{}/\\|@#$%\"&*-'\n",
    "  quase_limpo = [x.strip(lixo).lower() for x in lista]\n",
    "  return [x for x in quase_limpo if x.isalpha() or '-' not in x]\n",
    "\n",
    "print(len(palavras))\n",
    "palavras = limpar(palavras)\n",
    "print(len(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b916e",
   "metadata": {},
   "source": [
    "Quantidade de Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1503556",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = set(palavras)\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35830ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riqueza textual\n",
    "riqueza = len(vocabulario) / len(palavras)\n",
    "print(riqueza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094558c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionario do texto\n",
    "from collections import defaultdict\n",
    "\n",
    "def ocorrencias (lista_palavras):\n",
    "  dicionario = defaultdict(int)\n",
    "  for p in lista_palavras:\n",
    "    dicionario[p] += 1\n",
    "\n",
    "  return dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5506a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = ocorrencias(palavras)\n",
    "mf = sorted(dic.items(), key=lambda tupla:tupla[1], reverse = True)[:50]\n",
    "for palavra, n in mf:\n",
    "    print(palavra, '\\t', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa793dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "vazias = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentes_plenas = [x for x in mf if x[0].lower() not in vazias]\n",
    "frequentes_plenas"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
