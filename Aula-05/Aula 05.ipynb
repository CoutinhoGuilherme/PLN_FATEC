{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3717be0",
   "metadata": {},
   "source": [
    "Aula 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6aa6e",
   "metadata": {},
   "source": [
    "1 - Desenvolvimento conceitual - Corporas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd2759",
   "metadata": {},
   "source": [
    "Inicio do processamento do corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe1f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ler(nome_arquivo):\n",
    "  arquivo = open(nome_arquivo, 'r', encoding='utf-8')\n",
    "  conteudo_arquivo = arquivo.read()\n",
    "  arquivo.close()\n",
    "  return conteudo_arquivo\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5353d532",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/FatecMaua/6_Sem/ProcessamentoLinguagemNatural/2025.05 Ubirajara.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m texto = \u001b[43mler\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/drive/MyDrive/FatecMaua/6_Sem/ProcessamentoLinguagemNatural/2025.05 Ubirajara.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texto))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mler\u001b[39m\u001b[34m(nome_arquivo)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mler\u001b[39m(nome_arquivo):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m   arquivo = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnome_arquivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m   conteudo_arquivo = arquivo.read()\n\u001b[32m      4\u001b[39m   arquivo.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FatecMaua/6_Sem/ProcessamentoLinguagemNatural/2025.05 Ubirajara.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "texto = ler('/content/drive/MyDrive/FatecMaua/6_Sem/ProcessamentoLinguagemNatural/2025.05 Ubirajara.txt')\n",
    "print(len(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9466578",
   "metadata": {},
   "source": [
    "Buscador de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86952dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscador(alvo, texto):\n",
    "  texto = texto.replace('\\n', ' ')\n",
    "  texto = texto.replace('\\t', ' ')\n",
    "\n",
    "  ocorrencias = []\n",
    "  encontrado_aqui = texto.find(alvo, 0)\n",
    "\n",
    "  while encontrado_aqui > 0:\n",
    "    pos_inicial = encontrado_aqui - (40 - len(alvo))\n",
    "    trecho = texto[pos_inicial: pos_inicial + 80]\n",
    "\n",
    "    ocorrencias.append(trecho)\n",
    "\n",
    "    encontrado_aqui = texto.find(alvo, encontrado_aqui + 1)\n",
    "\n",
    "  return ocorrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e050d765",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m resultados = buscador(\u001b[33m'\u001b[39m\u001b[33m peito \u001b[39m\u001b[33m'\u001b[39m, \u001b[43mtexto\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trecho \u001b[38;5;129;01min\u001b[39;00m resultados:\n\u001b[32m      3\u001b[39m   \u001b[38;5;28mprint\u001b[39m(trecho)\n",
      "\u001b[31mNameError\u001b[39m: name 'texto' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "resultados = buscador(' peito ', texto)\n",
    "for trecho in resultados:\n",
    "  print(trecho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf11bac",
   "metadata": {},
   "source": [
    "Limpeza dos corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8f3c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m palavras = \u001b[43mtexto\u001b[49m.split()\n",
      "\u001b[31mNameError\u001b[39m: name 'texto' is not defined"
     ]
    }
   ],
   "source": [
    "palavras = texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7107dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limpar(lista):\n",
    "  lixo = '.,:;?!\"`()[]{}/\\|@#$%\"&*-'\n",
    "  quase_limpo = [x.strip(lixo).lower() for x in lista]\n",
    "  return [x for x in quase_limpo if x.isalpha() or '-' not in x]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ef723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teste = \"Corre-se atras do carro, corre se o carro for embora.\"\n",
    "word = teste.split()\n",
    "\n",
    "print(word)\n",
    "print(limpar(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f74287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(palavras) )\n",
    "palavras = limpar(palavras)\n",
    "print(len(palavras) )\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bfa235",
   "metadata": {},
   "source": [
    "2 -Demonstração de Estruturas Funcionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe4090",
   "metadata": {},
   "source": [
    "EX 1 - POS Tagging com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "frase = input(\"Insira uma frase, gramaticalmente correta: \")\n",
    "doc = nlp(frase)\n",
    "\n",
    "for token in doc:\n",
    "  print(f\"{token.text} -> {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b6130",
   "metadata": {},
   "source": [
    "EX 2 - POS Tagging com NLTK (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install nltk\n",
    "#nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "import nltk\n",
    "\n",
    "frase = input(\"Insira uma frase, coerente: \")\n",
    "tokens = nltk.word_tokenize(frase)\n",
    "\n",
    "pos_tags = nltk. pos_tag(tokens)\n",
    "\n",
    "for palavra, classe in pos_tags:\n",
    "  print(f'{palavra}->{classe}')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d648f41",
   "metadata": {},
   "source": [
    "EX 3 - Parsing de Dependência com spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy. load('pt_core_news_sm' )\n",
    "\n",
    "frase = \"0 gato preto dorme na cadeira\"\n",
    "doc = nlp(frase)\n",
    "\n",
    "for token in doc:\n",
    "  print(f\"{token.text} -> {token.dep_} -> {token.head.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90376ec",
   "metadata": {},
   "source": [
    "EX 4 - Análise de Dependências com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b98658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm' )\n",
    "\n",
    "frase = \"O gato preto dorme na cadeira.\"\n",
    "doc = nlp(frase)\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1681e4a",
   "metadata": {},
   "source": [
    "EX 5 - Análise de Constituência com NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ede3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk import Tree\n",
    "\n",
    "sintaxe = Tree('S', [\n",
    "  Tree('NP', [Tree('DET', ['O']), Tree('N', ['gato'])]),\n",
    "  Tree('VP', [Tree('V', ['dorme']),\n",
    "              Tree('PP', [Tree('P',['na']), Tree('NP',[Tree('N', ['cadeira'])])])])\n",
    "])\n",
    "\n",
    "sintaxe.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
