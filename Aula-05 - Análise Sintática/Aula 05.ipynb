{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3717be0",
   "metadata": {},
   "source": [
    "Aula 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6aa6e",
   "metadata": {},
   "source": [
    "1 - Desenvolvimento conceitual - Corporas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd2759",
   "metadata": {},
   "source": [
    "Inicio do processamento do corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ler(nome_arquivo):\n",
    "  arquivo = open(nome_arquivo, 'r', encoding='utf-8')\n",
    "  conteudo_arquivo = arquivo.read()\n",
    "  arquivo.close()\n",
    "  return conteudo_arquivo\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texto = ler('/content/drive/MyDrive/FatecMaua/6_Sem/ProcessamentoLinguagemNatural/2025.05 Ubirajara.txt')\n",
    "print(len(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9466578",
   "metadata": {},
   "source": [
    "Buscador de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86952dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscador(alvo, texto):\n",
    "  texto = texto.replace('\\n', ' ')\n",
    "  texto = texto.replace('\\t', ' ')\n",
    "\n",
    "  ocorrencias = []\n",
    "  encontrado_aqui = texto.find(alvo, 0)\n",
    "\n",
    "  while encontrado_aqui > 0:\n",
    "    pos_inicial = encontrado_aqui - (40 - len(alvo))\n",
    "    trecho = texto[pos_inicial: pos_inicial + 80]\n",
    "\n",
    "    ocorrencias.append(trecho)\n",
    "\n",
    "    encontrado_aqui = texto.find(alvo, encontrado_aqui + 1)\n",
    "\n",
    "  return ocorrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultados = buscador(' peito ', texto)\n",
    "for trecho in resultados:\n",
    "  print(trecho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf11bac",
   "metadata": {},
   "source": [
    "Limpeza dos corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7107dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limpar(lista):\n",
    "  lixo = '.,:;?!\"`()[]{}/\\|@#$%\"&*-'\n",
    "  quase_limpo = [x.strip(lixo).lower() for x in lista]\n",
    "  return [x for x in quase_limpo if x.isalpha() or '-' not in x]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ef723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teste = \"Corre-se atras do carro, corre se o carro for embora.\"\n",
    "word = teste.split()\n",
    "\n",
    "print(word)\n",
    "print(limpar(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f74287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(palavras) )\n",
    "palavras = limpar(palavras)\n",
    "print(len(palavras) )\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bfa235",
   "metadata": {},
   "source": [
    "2 -Demonstração de Estruturas Funcionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe4090",
   "metadata": {},
   "source": [
    "EX 1 - POS Tagging com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download pt_core_news_sm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "frase = input(\"Insira uma frase, gramaticalmente correta: \")\n",
    "doc = nlp(frase)\n",
    "\n",
    "for token in doc:\n",
    "  print(f\"{token.text} -> {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b6130",
   "metadata": {},
   "source": [
    "EX 2 - POS Tagging com NLTK (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install nltk\n",
    "#nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "import nltk\n",
    "\n",
    "frase = input(\"Insira uma frase, coerente: \")\n",
    "tokens = nltk.word_tokenize(frase)\n",
    "\n",
    "pos_tags = nltk. pos_tag(tokens)\n",
    "\n",
    "for palavra, classe in pos_tags:\n",
    "  print(f'{palavra}->{classe}')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d648f41",
   "metadata": {},
   "source": [
    "EX 3 - Parsing de Dependência com spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy. load('pt_core_news_sm' )\n",
    "\n",
    "frase = \"0 gato preto dorme na cadeira\"\n",
    "doc = nlp(frase)\n",
    "\n",
    "for token in doc:\n",
    "  print(f\"{token.text} -> {token.dep_} -> {token.head.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90376ec",
   "metadata": {},
   "source": [
    "EX 4 - Análise de Dependências com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b98658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm' )\n",
    "\n",
    "frase = \"O gato preto dorme na cadeira.\"\n",
    "doc = nlp(frase)\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1681e4a",
   "metadata": {},
   "source": [
    "EX 5 - Análise de Constituência com NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ede3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk import Tree\n",
    "\n",
    "sintaxe = Tree('S', [\n",
    "  Tree('NP', [Tree('DET', ['O']), Tree('N', ['gato'])]),\n",
    "  Tree('VP', [Tree('V', ['dorme']),\n",
    "              Tree('PP', [Tree('P',['na']), Tree('NP',[Tree('N', ['cadeira'])])])])\n",
    "])\n",
    "\n",
    "sintaxe.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
